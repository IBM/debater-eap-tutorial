{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a14582c-65dc-4d0b-a7b9-4d030844fd23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using *Key Point Summarization* for analyzing and finding insights in a survey data \n",
    "When you have a large collection of texts representing peopleâ€™s opinions (such as product reviews, survey answers or social media), it is difficult to understand the key issues that come up in the data. Going over thousands of comments is prohibitively expensive.  Existing automated approaches are often limited to identifying recurring phrases or concepts and the overall sentiment toward them, but do not provide detailed or actionable insights. \n",
    "\n",
    "In this tutorial you will gain hands-on experience in using *Key Point Summarization* (KPS) for analyzing and deriving insights from open-ended comments.  \n",
    "\n",
    "The data we will use is [a community survey conducted in the city of Austin](https://data.austintexas.gov/dataset/Community-Survey/s2py-ceb7). In this survey, the citizens of Austin were asked \"If there was ONE thing you could share with the Mayor regarding the City of Austin (any comment, suggestion, etc.), what would it be?\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab28f81",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85aed7e",
   "metadata": {},
   "source": [
    "### 1.1 Setup\n",
    "\n",
    "Let's first import all the required packages for this tutorial and initialize the *Key Point Summarization* client. The client prints information using a logger and a suitable verbosity level should be set. The client object is configured with an API key. To receive an API key please send an email to *yoavka@il.ibm.com* and we'll be happy to provide it. In the code below it is stored in the enviroment variable *KPS_API_KEY* (you may also modify the code and place the api-key directly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510552af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from debater_python_api.api.clients.keypoints_client import KpsClient, KpsJobFuture\n",
    "from debater_python_api.api.clients.key_point_summarization.KpsResult import KpsResult\n",
    "import os\n",
    "import pandas as pd\n",
    "import json \n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "KpsClient.init_logger()\n",
    "api_key = os.environ['KPS_API_KEY']\n",
    "host = 'https://keypoint-matching-backend.debater.res.ibm.com'\n",
    "keypoints_client = KpsClient(api_key, host)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71725a3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 Read the data\n",
    "Let's read the data from *dataset_austin.csv* file, which holds the Austin survey dataset, and print the first comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = pd.read_csv('./dataset_austin.csv')\n",
    "\n",
    "print(f'There are {len(comments_df)} comments in the dataset')\n",
    "print(dict(comments_df.iloc[0,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b55e5e",
   "metadata": {},
   "source": [
    "Each comment has a unique_id 'id', a 'text', a 'year' and a 'Council_District'. The *Key Point Summarization* service is able to run over hundreds of thousands of comments. However, to provide good user experience, the KPS evaluation service is limited to 1000 comments per run, each comment with up to 3000 chars. You may request to increase this limit if needed. \n",
    "\n",
    "We will choose a sample of 1000 comments from 2016 for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb6777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df = comments_df.dropna()\n",
    "comments_df = comments_df[comments_df.text.apply(lambda x: 0<len(str(x))<=3000)]\n",
    "\n",
    "comments_2016_df = comments_df[comments_df['year'] == 2016]\n",
    "sample_size = 1000\n",
    "comments_2016_sample_df = comments_2016_df.sample(n = sample_size, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e11f1f-e795-4cee-a311-7ec801899d38",
   "metadata": {},
   "source": [
    "## 2. Run the full KPS flow and generate results\n",
    "The simplest way to run KPS is using the method **keypoints_client.run_full_kps_flow()**, which serves as an excellent starting point. To do so, you only need to provide a collection of textual comments and a distinct domain name (comprised of alphanumeric characters, spaces, or underscores). If you wish to reuse a domain from a previous run, you will first need to delete it via **keypoints_client.delete_domain_cannot_be_undone(domain=domain)**. \n",
    "\n",
    "Using this method, KPS extracts the key points from the provided data and matches each sentence in the input comments with its corresponding matching key points.\n",
    "\n",
    "By default, the service performs stance analysis: it runs for positive (pro) and for negative (con) sentences seperately, and returns a merged result containing key points from both stances. To disable the stance analysis and run on all sentences together, add the parameter **stance=no-stance** to the **run_full_kps_flow** method.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97aa7a7-d15c-47d0-99e8-d45fcb773504",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "domain = \"austin_demo_full\"\n",
    "comments_texts_2016 = list(comments_2016_sample_df['text'])\n",
    "kps_result_2016 = keypoints_client.run_full_kps_flow(domain, comments_texts_2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1729f422-c946-4bd9-90aa-01b47663d5a5",
   "metadata": {},
   "source": [
    "kps_result_2016 is a KpsResult object. Let's print the top 40 key points, and the top three matched sentences per key point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c71fd52-8f5a-4647-aa72-7644e4d42914",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_result_2016.print_result(n_sentences_per_kp = 3, title = \"Austin sample 2016 full flow\", n_top_kps = 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64542c35-5fbb-43c8-8ecc-370ce6dac760",
   "metadata": {},
   "source": [
    "In the second line we can see that 67% of the comments were matched, i.e., had at least one sentence matched to a key point.\n",
    "For each key point, this method prints the number of matched comments, its stance (pro or con) and the top matching sentences which present some of main points that were raised regarding the key point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2e98d-3081-4cd8-ac1d-620a9b07fdbc",
   "metadata": {},
   "source": [
    "## 3. KpsResult Object and result processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba85c328-9d62-4db3-b2ae-f0d0749f5178",
   "metadata": {},
   "source": [
    "The *KpsResult* object stores all the information about the job and the results. It can be used to generate several types of reports and to compare different results. All the reports generated in this section are available in the folder \"kps_results\".\n",
    "\n",
    "The KpsResult can be saved to a file and loaded from a file via the **load** and **save** methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175336f-b45a-45f7-9eaa-8bcbbb06596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"kps_results/kps_result_2016.json\"\n",
    "kps_result_2016.save(json_file) \n",
    "kps_result_2016 = KpsResult.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637011ca-0b3f-49af-ab84-6ad1dbe5c84e",
   "metadata": {},
   "source": [
    "### 3.1 Result Summary\n",
    "The result summary presented in the attribute *summary_df* displays the aggregated information per key point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9922987b-6310-4f1e-86ba-cf53a56855c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_result_2016.summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e3d9a1-94ce-49ae-821e-530060da33e7",
   "metadata": {},
   "source": [
    "The report displays:  \n",
    "- `key_point`: the list of generated key points, sorted by their saliance.\n",
    "- `#comments`: the number of comments matched to the key point (comments that have at least one sentence matched to the key point).  \n",
    "- `comments_coverage`: the percentage of comments matched to it (out of the entire set of comments sent to the job).  \n",
    "- `#sentences`: the number of the sentences matched to the key point.  \n",
    "- `sentences_coverage`: the percentage of the sentences matched to the key point (out of the entire set of sentences in the comments sent to the job).\n",
    "- `stance`: the key point's stance (if stance analysis was performed).\n",
    "- `kp_id`: the key point's id.  \n",
    "- `parent_id`: The analysis also creates a key point tree-structured hierarchy. The parent_id column shows the kp_id of the parent of the key point. For example, the key points *Please plan better for growth on our roadways!* and *driving in Austin is terrible* are under the parent key point *Improve traffic flow.*  \n",
    "- `n_comments_subtree`: how many comments are in the subtree of the key point (matched to the key point or any of its descendants).  \n",
    "\n",
    "\n",
    "In addition to the individual key points, in the last rows we can find the statistics of total and matched number of sentences and comments for each stance, starting with \\*: in the current example, there are 1000 comments and 1813 sentences in total, 668 and 920 of them are matched to at least one key point, respectively. Out of those, 881 comments have sentences classified as con, and overall 1450 sentences are classified as con. 655 comments and 898 sentences are matched to con key points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7db1eef-8359-4721-a400-c1659e65cb7d",
   "metadata": {},
   "source": [
    "### 3.2 Docx report\n",
    "You can also generate a Microsoft Word document that shows the key point hierarchy visually and presents the sentences matched to each key point as a user-friendly report. it can be generated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e82d0e-4da7-44ef-91f8-0559594fa9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_result_2016.generate_docx_report(output_dir = \"kps_results\", result_name=\"kps_result_2016\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d852ed9-1e3a-440f-9283-972c6653bfb0",
   "metadata": {},
   "source": [
    "Note that this report displays only the more salient key points (that are matched to at least 5 sentneces) so there might be some differences from the summary report. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d056c11b-612c-41f6-9b09-e193e8e0edb7",
   "metadata": {},
   "source": [
    "### 3.3 Full report\n",
    "\n",
    "The attribute *result_df* stores the full results. Each row stores a pair of a key point, a matched sentence, their match_score and all the information regarding the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3240c2-fdda-4814-8cac-12c94a22405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_result_2016.result_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6103f0a2-8c27-4400-b3e8-a9aa18ce3fb8",
   "metadata": {},
   "source": [
    "It's also possible to generate all three reports together. You need to provide the output_dir and the result name, and the reports will be written to files with the appropriate suffixes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f56a0ba-ae5a-4245-bad9-60e5743f1524",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_result_2016.export_to_all_outputs(output_dir=\"kps_results\", result_name=\"kps_result_2016\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f967d-9e05-4cb7-993b-d02ea245b63b",
   "metadata": {},
   "source": [
    "More advanced capabiliteis of the KpsResult Object will be presented later: \n",
    " - Job management related options (Section 5). \n",
    " - Comparative analysis (Section 6)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4b8dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4 Run KPS step by step\n",
    "In order to customize the key points summarization service and fully exploit its caching and comparitive capabilities, we must run the service in a staged manner. Let's dive into each step and understand the KPS flow.  \n",
    "\n",
    "### 4.1 Create a domain\n",
    "The *Key Point Summarization* service stores the data (and cached results) in a *domain*. A user can create several domains, one for each dataset. Domains are only accessible to the user who created them.\n",
    "\n",
    "Create a domain using the **keypoints_client.create_domain(domain=domain, domain_params={})** method. \n",
    "Several parameters can be passed in the domain_params dictionary. In most cases, the default params need not change, and provide satisfactory results. Full documentation of the supported *domain_params* can be found [here](kps_parameters.pdf).\n",
    "\n",
    "By default, an exception is raised if the domain already exists. To avoid this exception, add the parameter **ignore_exists=True** to the method. Note that in this case the domain_params are not updated and the existing domain remains the same. \n",
    "\n",
    "In this tutorial we will first delete the domain to make sure that we start with an empty domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4956e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'austin_demo'\n",
    "keypoints_client.delete_domain_cannot_be_undone(domain=domain)\n",
    "keypoints_client.create_domain(domain=domain, domain_params={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd618c78",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* The domain must be comprised of alphanumeric characters, spaces, or underscores. \n",
    "* We can delete a domain we no longer need using: **keypoints_client.delete_domain_cannot_be_undone(domain=domain)**.\n",
    "* Each domain has a state: it stores all comments previously uploaded into it and a cache with all the computations performed over this data.\n",
    "* If we want to restart and run over the domain from scratch (no comments and no cache), we can delete the domain and then re-create it. Keep in mind that the cache is also cleared and consecutive runs will take longer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82c51cd",
   "metadata": {},
   "source": [
    "### 4.2 Upload comments into the domain\n",
    "Upload the comments into the domain using the **keypoints_client.upload_comments(domain=domain, comments_ids=comments_ids, comments_texts=comments_texts)** method. This method receives the domain, a list of comment_ids and a list of comment_texts. When uploading comments into a domain, the *Key Point Summarization* service splits the comments into sentences and runs a minor cleansing on them. If you want to split the comments into sentences or clean them yourself, you can use the *split_comments* or *clean_comments* domain_params when creating the domain to disable this functionality in KPS (see details [here](kps_parameters.pdf)).\n",
    "\n",
    "Note that:\n",
    "* Comments_ids must be unique strings comprised of alphanumeric characters, spaces or underscores.\n",
    "* The number of comments_ids must match the number comments_texts\n",
    "* Comments_texts must not be longer than 3000 characters\n",
    "* Uploading the same comment several times (same domain + comment_id + comment_text) is not a problem and the comment is only processed once.\n",
    "* Uploading the same comment_id with a different comment_text will raise an exception. \n",
    "\n",
    "After being uploaded to the domain, the comments can take some time to be processed. \n",
    "The method runs in a synchronous manner and returns only after all the comments are processed. In the meantime, the status of the processing is printed on screen.\n",
    "For information about running KPS asynchronously, see Section 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da5d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_texts_2016 = list(comments_2016_sample_df['text'])\n",
    "comments_ids_2016 = list(comments_2016_sample_df['id'].astype(str))\n",
    "keypoints_client.upload_comments(domain=domain, comments_ids=comments_ids_2016, comments_texts=comments_texts_2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fed26a-727c-4834-afe3-2d10d3fb127f",
   "metadata": {},
   "source": [
    "To examine the processed data, we can download the processed sentences and save them into a csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9101d6-ed50-4821-a38c-8103691d2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df = keypoints_client.get_sentences_for_domain(domain=domain)\n",
    "sentences_df.to_csv(f\"kps_results/{domain}_sentences.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da852b04",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.3 Run a KPS job\n",
    "Run a *Key Point Summarization* job using the **keypoints_client.run_kps_job(domain=domain)** method. \n",
    "This method receives:\n",
    "* The domain.\n",
    "* Optional *comment_ids*: by default, the summarization is performed over all comments in the domain. If we need to run over a subset of the comments (split the data by different GEOs/users types/timeframes etc.) we can pass a list of their comments_ids.\n",
    "* Optional *run_params*: a dictionary with various parameters for customizing the job (see Section 4.4).\n",
    "* Optional *stance*: unlike in the run_full_kps_flow method presented in Section 2, here no stance analysis is performed by default. see Section 4.5 for stance customization.\n",
    "* Optional *description*: a description of the job to appear in the user report (see Section 5.1).  \n",
    "\n",
    "The system extracts the key points from the input comments, and matches each sentence in the comments with all its matching key points.\n",
    "The job runs in a synchronous manner, prints the progress to the screen and returns the KpsResult eventually.   \n",
    "For information about running KPS asynchronously, see Section 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948bf751",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_result_2016_no_stance = keypoints_client.run_kps_job(domain = domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74421ee6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's print the top 20 key points in the results: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211f20cb-fe10-4282-a54c-1e2618be72c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_result_2016_no_stance.print_result(n_sentences_per_kp = 3, title = \"Austin sample 2016\", n_top_kps = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc10ed9-3a2b-44b9-9375-2e4a6a5bf003",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.4 Modify the run_params to customize the summary\n",
    "Each domain has a cache that stores all the intermediate results that are calculated during the summarization process. Therefore modifing the run_params and running another summarization is usually faster. \n",
    "\n",
    "Full documentation of the supported *run_params* can be found [here](kps_parameters.pdf).\n",
    "Some of the notable options:\n",
    "* By default, key points are extracted automatically. When we want to provide the key points and match all the sentences to them we can pass key_points parameter: **run_param['key_points'] = [...]**. This enables a mode of work named human-in-the-loop where we first automatically extract key points, then we manually edit them (refine non-perfect key points, remove duplicated and add missing ones) and then run again, this time providing the edited keypoints as a given set of key points.\n",
    "* It is also possible to provide key points and let KPS add additional missing key points. To do so pass the key points to the key_point_candidates parameter: **run_param['key_point_candidates'] = [...]** (see Section 6.2 for an elaborated example).\n",
    "* Change the lengths of the required key points and the sentences participating in the summarization.\n",
    "* The **mapping_policy** is used when mapping all sentences to the final key points: the default value is **NORMAL**. Changing to **STRICT** will cause only the sentence and key point pairs with very high matching confidence to be considered matched, increasing precision but potentially decreasing coverage. Changing it to **LOOSE** will do the opposite and match pairs with lower confidene. \n",
    "\n",
    "Let's run with the 'LOOSE' mapping policy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d24fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = {'mapping_policy':'LOOSE'}\n",
    "kps_result_loose = keypoints_client.run_kps_job(domain=domain, run_params=run_params)\n",
    "kps_result_loose.print_result(n_sentences_per_kp=3, title='Austin sample 2016 LOOSE', n_top_kps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61557e9",
   "metadata": {},
   "source": [
    "By changing the mapping policy to **LOOSE** the comments' coverage was increased from 74.5% to 82%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f41cc-42d5-4ed6-99b0-af20a3e02e89",
   "metadata": {},
   "source": [
    "### 4.5 Add stance analysis to the summarization\n",
    "\n",
    "In many usecases (surveys, customer feedback, etc.) the comments have positive and/or negative stances, and it is useful to create a KPS on each stance seperatly. Most stance detection models don't perform too well on survey data since the comments have many \"suggestions\" in them. These suggestions tend to be classified by the models as positives, while the user suggests a point for improvement. For that end we trained a stance-model that handles suggestions well and classifies each sentence as either 'Positive', 'Negative', 'Neutral' or 'Suggestion'. We treat Suggestions as negatives and run two separate summarizations, first over 'Positive' sentences (pro) and second over 'Negative' and 'Suggestions' sentences (con).\n",
    "\n",
    "This has the following advantages:\n",
    "\n",
    "* Generate separate positive/negative key points that show clearly what works well and what needs to be improved.\n",
    "* Filters-out neutral sentences that usually don't contain valuable information.\n",
    "* Helps the matching model avoid stance mistakes (matching a positive sentence to a negative key point and vice-versa).\n",
    "\n",
    "In some cases, we might want to run over a single stance. For example, if we are only interested in points for improvement.\n",
    "In order to run for each stance seperately, use the **stance** parameter in **run_kps_job**. the options are either \"pro\", \"con\", or \"no-stance\" (default). For example, to run only on the \"pro\" sentences, run **keypoints_client.run_kps_job(domain=domain, stance=\"pro\")**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63074d36-db77-4b48-a5aa-7f38c5b58feb",
   "metadata": {},
   "source": [
    "To generate a merged pro and con result use the **run_kps_job_both_stances** method.\n",
    "This method starts two seperate jobs simultenously, one for *pro* and one for *con*. It later unifies the results and returns the merged result object (similar to the default behviour of **run_kps_full_flow**).\n",
    "This method receives: \n",
    "* The domain.\n",
    "* comments_ids - optional, as in *run_kps_job*.\n",
    "* desription - optional, as in *run_kps_job*, stance is appended to the description of each job.\n",
    "* run_params_pro - optional run_params to be sent to the *pro* job.\n",
    "* run_params_con - optional run_params to be sent to the *con* job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65391e20-8c7c-4341-ae3c-89987e4e976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_result_2016_merged = keypoints_client.run_kps_job_both_stances(domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523a7d0",
   "metadata": {},
   "source": [
    "## 5. Jobs management\n",
    "\n",
    "### 5.1 User report\n",
    "The user report stores all the information about existing domains and all past and present KPS jobs. \n",
    "To fetch it and print to screen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcca18-2700-4d52-9eb2-5cbe9f7de3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = keypoints_client.get_full_report()\n",
    "keypoints_client.print_report(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296c24a-6e75-4310-812b-d9eb505caf81",
   "metadata": {},
   "source": [
    "### 5.2 job_id\n",
    "Each job has a unique job_id which is useful for the jobs managements, and can be obtained in several ways:\n",
    "* It's printed to the screen when the job starts and in every progress update.\n",
    "* From the user report.\n",
    "* When running asyncronously (see Section 7)\n",
    "* From the KpsResult object, using the **get_stance_to_job_id()** method. Note that the KpsResult can either store the information from a single job (when running on a single stance or no stance) or two jobs (for combined pro and con results). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d09a4-e54f-43e0-9c74-7ce9fdcad894",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kps_result_2016_merged.get_stance_to_job_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbbc5d0-1b43-4204-9cf4-4d5ff12af752",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kps_result_2016_no_stance.get_stance_to_job_id())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ebe2f-7c6d-4bdb-881c-27483361d55e",
   "metadata": {},
   "source": [
    "### 5.3 Canceling a job\n",
    "Simply exiting the program after the job is sent does not cancel the job: it keeps running on the server, consuming resources. In order to cancel a job, use: \n",
    "* **keypoints_client.cancel_kp_extraction_job(\\<job_id\\>)**\n",
    "\n",
    "It is also possibe to stop all jobs in a domain, or even all jobs in all domains (this might be simpler since there is no need of the job_id):\n",
    "\n",
    "* **keypoints_client.cancel_all_extraction_jobs_for_domain(\\<domain\\>)**\n",
    "* **keypoints_client.cancel_all_extraction_jobs_all_domains()**\n",
    "\n",
    "\n",
    "### 5.4 Fetching the results of a previous job\n",
    "If the program terminated unexpectedly after the job was sent, you can still fetch the results using:\n",
    "* **kps_result = keypoints_client.get_results_from_job_id(\\<job_id\\>)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9441e404-9516-4e97-bec4-94b2b1f912f1",
   "metadata": {},
   "source": [
    "### 5.5 Fetching unmatched sentences\n",
    "The KpsResult object stores only the sentences that were matched to at least one key point. In order to get the list of sentences that were not matched to any key point, the client needs to be called with the method **get_unmapped_sentences_for_kps_result(\\<kps_result\\>)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a2536-2b6e-4220-8ac1-a3fd43ba5b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmapped_sentences_df = keypoints_client.get_unmapped_sentences_for_kps_result(kps_result_2016_no_stance)\n",
    "unmapped_sentences_df.to_csv(\"kps_results/kps_result_2016_merged_unmapped_sentences.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d2d05e-4e74-4765-8826-b9f2a36e1720",
   "metadata": {},
   "source": [
    "Note that this will work only if the domain on which the job(s) ran still exists, and thus is not supported when using the **run_full_kps_flow** method. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff92aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Comparative analysis with KPS\n",
    "\n",
    "The KPS service allows us to easily perform comparisons between subsets of our data and to perform trend analysis over data collected in different times. Let's explore two of these options: \n",
    "\n",
    "### 6.1 Compare comment subsets\n",
    "So far, we ran over all the sampled comments for 2016. Now, let's say we want to perform the analysis over the same data by district, and compare the feedback of the residents of district 7 with the feedback of the residents of district 10. All we need is our previous KpsResult and the comment_ids of each subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d41202c-b5d6-452b-aa9c-86aa829b8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_ids_district_7 = list(comments_2016_sample_df[comments_2016_sample_df[\"Council_District\"]==7][\"id\"].astype(str))\n",
    "comment_ids_district_10 = list(comments_2016_sample_df[comments_2016_sample_df[\"Council_District\"]==10][\"id\"].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60284d-a99f-47dc-a7c1-5c5101d83d67",
   "metadata": {},
   "source": [
    "Now, we can compare the full result and the result from each district, using the method **compare_with_comment_subsets()**.\n",
    "This method receives a dictionary with mappings from subset names to sets of comment ids, and performs the comparison between the full result and the subset results. For the full result and for each of the subsets, you can see the number and percentage of the comments that match each key point. Let's create the comparison df and print the top 20 key points and the summary row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb22305d-b84b-40b9-8982-6a6441a4d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets_dict = {\"district_7\":comment_ids_district_7, \"district_10\":comment_ids_district_10}\n",
    "comparison_df = kps_result_2016_no_stance.compare_with_comment_subsets(subsets_dict)\n",
    "pd.concat([comparison_df.head(20),comparison_df.tail(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82659631-b225-4162-878f-e43eee3f46a3",
   "metadata": {},
   "source": [
    "From the percentage displayed in the comparison, it is apparent that the residents of district 10 are more concerned about the traffic issues in Austin, while the residents of district 7 care more about affordable housing.\n",
    "\n",
    "Using this method, we can compare results over subsets of the data in the same domain with a single KPS job. The subsets can be data from different GEOs, different organizations, different times, different users (e.g. promoters/detractors) etc.).\n",
    "\n",
    "This has several advantages over running a separate job for each subset:\n",
    "- The service only needs to be called once.\n",
    "- By running a single job, we generate a single key points list which makes it possible to compare between the subsets.\n",
    "- KPS generates better results for larger datasets, so running over the full data allows to get reacher key points with better coverage. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41727d63-8428-4014-bf1d-eac250627463",
   "metadata": {},
   "source": [
    "### 6.2 Run KPS incrementally \n",
    "\n",
    "A year passed, and we collect additional data (from 2017). We would like to analyze the new data and compare it to the data from 2016. \n",
    "We can upload all the comments from 2017 to the same domain (\"austin_demo\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f9111",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_2017_df = comments_df[comments_df['year'] == 2017]\n",
    "\n",
    "sample_size = 1000\n",
    "comments_2017_sample_df = comments_2017_df.sample(n = sample_size, random_state = 1)\n",
    "\n",
    "domain = 'austin_demo'\n",
    "comments_texts_2017 = list(comments_2017_sample_df['text'])\n",
    "comments_ids_2017 = list(comments_2017_sample_df['id'].astype(str))\n",
    "keypoints_client.upload_comments(domain=domain, comments_ids=comments_ids_2017, comments_texts=comments_texts_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cdd33f",
   "metadata": {},
   "source": [
    "We can now run a new summarization job over all the data in the domain, as we did before, and automatically extract new key points. Then we can use the **compare_with_comment_subsets** method to compare between the data subsets, as we learned in the previous section. We can assume that some key points will be identical to the key points extracted from the 2016 data, some will be similar and some key points will be new.\n",
    "\n",
    "A better option is to run a new summarization but provide the keypoints from the 2016 summarization and let *Key Point Summarization* add new key points from the 2017 data if there are such. One benefit of this approach is that the new result will mostly use 2016 key point and we will be consistent with our previous results. Another major benefit for this approach is run-time. 2016 data was already analyzed with these key points and since we have a cache in place, much of the computation can be avoided. The 2016 key points can be provided via the: **run_param['key_point_candidates'] = [...]** parameter, passing a list of strings, or we can use: **run_param['key_point_candidates_by_job_ids'] = [\\<job_id1\\>,...]** and provide a list of previous job_ids. KPS will take the key points from the jobs' result automatically.\n",
    "\n",
    "For simplicity, we'll run over the result without the stance analysis. We can also use the incremental approach when running on both stances: we will need to provide the job_id of the positive summarization of 2016 in the run_params_pro and the job_id of negative summarization of 2016 in the run_params_con when running on all sentences from 2016+2017.\n",
    "\n",
    "First, let's extract the job id from the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630e28e-438a-4af0-809a-90d11a16932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stance_to_job_id = kps_result_2016_no_stance.get_stance_to_job_id()\n",
    "print(stance_to_job_id)\n",
    "job_id_2016_no_stance = stance_to_job_id[\"no-stance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0b2329-fe72-4811-a831-4dc4cc8f558c",
   "metadata": {},
   "source": [
    "Now, let's run the job and print the top 20 key points in the comparison df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ff7fd-6724-4587-a7ce-fb6f0e9acfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = {'key_point_candidates_by_job_ids': [job_id_2016_no_stance]}\n",
    "kps_result_2016_2017 = keypoints_client.run_kps_job(domain, run_params=run_params)\n",
    "subsets_dict = {\"2016\":comments_ids_2016, \"2017\":comments_ids_2017}\n",
    "comparison_df = kps_result_2016_2017.compare_with_comment_subsets(subsets_dict)\n",
    "pd.concat([comparison_df.head(20),comparison_df.tail(1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8412e2",
   "metadata": {},
   "source": [
    "\n",
    "Alternatively, if you don't care about the 2016+2017 combination and only want to compare the 2016 and the 2017 data, You can use the **comments_ids** parameter in the **run_kps_job** method, to run on a subset of the comments in the domain. Let's do that and run summarization over the comments from 2017 independantly. We will provide the key points from 2016 as candidates, since we want to able to compare between the the two results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d574a490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_params = {'key_point_candidates_by_job_ids': [job_id_2016_no_stance]}\n",
    "kps_result_2017_no_stance = keypoints_client.run_kps_job(domain, run_params=run_params, comments_ids = comments_ids_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c11729-a19c-41ca-9000-ec5c51a41bc7",
   "metadata": {},
   "source": [
    "Now, we can compare the kps_result_2016_no_stance with the kps_result_2017_no_stance using the **compare_with_other_results** method. This method receives the title for the current result and a dictionary mapping from results name to KpsResult objects, and returns the comparison table. If the comparison is with a single other result, the change percent is also displayed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8daaef-3aac-43a0-bae7-7b3ef323e3ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "other_results_dict = {\"2017\": kps_result_2017_no_stance}\n",
    "comparison_df = kps_result_2016_no_stance.compare_with_other_results(this_title=\"2016\", other_results_dict=other_results_dict)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb17d963-a2d0-461d-a8fa-82a0d62a82b9",
   "metadata": {},
   "source": [
    "In the first 63 rows we can see the key points from 2016 applied to the data from 2017. Then, key points from 2017 that are not covered by the 2016 data are added, e.g. *\"Focus on basic services\"* and *\"Austin is not managing growth well.\"*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d82f0f0-e408-4967-be7b-cb323e56a3fd",
   "metadata": {},
   "source": [
    "## 7. Running KPS asynchronously\n",
    "\n",
    "It is also possible to upload comments and run KPS jobs asynchronously. This can be useful when you want to start several jobs simultaneously, and then later collect the results.\n",
    "\n",
    "Let's create a new domain for sake of the demonstaration. Note that this is not required, as async and sync calls can be used on the same doamin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70882ed7-8360-470a-9aa7-a2328b72e199",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'austin_demo_async'\n",
    "keypoints_client.delete_domain_cannot_be_undone(domain=domain)\n",
    "keypoints_client.create_domain(domain=domain, domain_params={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2053676-6931-4977-aa26-9adae6a17dfc",
   "metadata": {},
   "source": [
    "### 7.1 Uploading comments asynchronously\n",
    "\n",
    "In order to start loading comments, use the *upload_comments_async* method: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756ae827-73b5-43bd-87ad-185019342cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_texts = list(comments_2016_sample_df['text'])\n",
    "comments_ids = list(comments_2016_sample_df['id'].astype(str))\n",
    "keypoints_client.upload_comments_async(domain=domain, comments_ids=comments_ids, comments_texts=comments_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd476d4",
   "metadata": {},
   "source": [
    "The method uploads the comments and returns immediately. We must wait until all comments finish processing before starting a KPS job. This can be checked via the **are_all_comments_processed(domain=domain)** method, which prints the upload status and returns True when the domain is ready for running jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e2b15-9631-496f-acfa-43677e50cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keypoints_client.are_all_comments_processed(domain))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fe93f-ba26-447d-ab67-b2c8c07700d3",
   "metadata": {},
   "source": [
    "You can also use the **wait_till_all_comments_are_processed(domain=domain)** method, that returns only after the comments are processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ea81e5-1380-44df-adce-fd112e527e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_client.wait_till_all_comments_are_processed(domain=domain) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caef34d0-0fa9-4858-93ba-63c00a92e543",
   "metadata": {},
   "source": [
    "### 7.2 Running KPS jobs asynchronously\n",
    "\n",
    "In order to start a job asynchronously, use the **run_kps_job_async** method. This method receives the same arguments as **run_kps_job**, but returns right after a the job is sent to the server, returning a future object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a784aab-d51b-48e5-8f24-69656b637420",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = keypoints_client.run_kps_job_async(domain=domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed9c0ac-1040-451a-b375-4f0c3a49bb81",
   "metadata": {},
   "source": [
    "Use the returned future and wait till results are available using the **kps_result = future.get_result()** method. The method waits for the job to finish and eventually returns the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9260613b-1204-446b-9d37-2555c333e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_result_async = future.get_result(high_verbosity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d2b13b-9b8e-46e0-adf0-13265c113628",
   "metadata": {},
   "source": [
    "The future object can also be used to obtain the job_id, via the **future.get_job_id()** method.\n",
    "\n",
    "To generate a merged pro and con KpsResult, generate a separate pro_result and con_result using the above flow, and then use the method **KpsResult.get_merged_pro_con_results(pro_result, con_result)**. It's important to only merge pro and con results that were obtained over the same domain and using the same set of comments, otherwise an error will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aaafc9-57cf-4153-8c07-8e9adaa66732",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_pro = keypoints_client.run_kps_job_async(domain, stance=\"pro\")\n",
    "future_con = keypoints_client.run_kps_job_async(domain, stance=\"con\")\n",
    "result_pro = future_pro.get_result()\n",
    "result_con = future_con.get_result()\n",
    "result_async_merged = KpsResult.get_merged_pro_con_results(pro_result=result_pro, con_result=result_con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00698571-ebbe-4b82-9472-a680de9f1ae4",
   "metadata": {},
   "source": [
    "## 8. Cleanup\n",
    "If you finished the tutorial and no longer need the domains and the results, cleaning up is always advised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27faf5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_client.delete_domain_cannot_be_undone(domain='austin_demo')\n",
    "keypoints_client.delete_domain_cannot_be_undone(domain='austin_demo_async')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dbc94e",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "In this tutorial, we showed how to use the *Key Point Summarization* service, and how it provides detailed insights over survey data right out of the box - significantly reducing the effort required by a data scientist to analyze the data. We also demonstrated key *key point Summarization* features such as how to modify the summarization parameters and increase coverage, how to use the stance-model and create per-stance results, how to incrementally add new data and how to compare between different subsets of the data.\n",
    "\n",
    "Feel free to contact us for questions or assistance: *yoavka@il.ibm.com*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbb220b-1fc6-453a-9c00-3c6a37c334b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
