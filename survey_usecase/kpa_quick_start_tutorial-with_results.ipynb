{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f1683b",
   "metadata": {},
   "source": [
    "# Using *Key Point Analysis* service for analyzing and finding insights in a survey data \n",
    "When you have a large collection of texts representing people’s opinions (such as product reviews, survey answers or  social media), it is difficult to understand the key issues that come up in the data. Going over thousands of comments is prohibitively expensive.  Existing automated approaches are often limited to identifying recurring phrases or concepts and the overall sentiment toward them, but do not provide detailed or actionable insights.\n",
    "\n",
    "In this tutorial you will gain hands-on experience in using *Key Point Analysis* (KPA) for analyzing and deriving insights from open-ended answers.  \n",
    "\n",
    "The data we will use is a community survey conducted in the city of Austin (https://data.world/cityofaustin/mf9f-kvkk). In this survey, the citizens of Austin were asked \"If there was ONE thing you could share with the Mayor regarding the City of Austin (any comment, suggestion, etc.), what would it be?\". "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab28f81",
   "metadata": {},
   "source": [
    "## 1. Run *Key Point Analysis* (data from 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71725a3a",
   "metadata": {},
   "source": [
    "### 1.1 Read the data and run *key point analysis*  over it\n",
    "Let's read the data from *dataset_austin.csv* file, which holds the Austin survey dataset, and print the first comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c6f083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3187 comments in the dataset\n",
      "{'id': '1', 'year': '2016', 'text': \"Dissatisfied traffic and with traffic, timing of street lights.  EXTREMELY dissatisfied with cit govt. interfering in local businesses (Uber/Lyft, income property owners).  Also, extremely dissatisfied with all the free handouts to people who are perfectly capable of earning their own money.  I'm very dissatisfied with the liberal leaning local politicians.\"}\n"
     ]
    }
   ],
   "source": [
    "from debater_python_api.api.clients.keypoints_client import KpAnalysisClient, KpAnalysisUtils, KpAnalysisTaskFuture\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "\n",
    "with open('./dataset_austin.csv') as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    comments = [dict(d) for d in reader]\n",
    "\n",
    "print(f'There are {len(comments)} comments in the dataset')\n",
    "print(comments[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b55e5e",
   "metadata": {},
   "source": [
    "Each comment is a dictionary with an unique_id 'id' and 'text' and a 'year'. We will first remove all comments with text longer than 1000 characters since this is a systme's limit. Then we will filter the comments and take the ones from 2016. \n",
    "\n",
    "The *Key Point Analysis* service is able to run over hundreds of thousands of sentences, however since the computation is heavy in resources (particularly GPUs) the trial version is limited to 1000 comments. You may request to increase this limit if needed. Since we want the tutorial to be relativly fast and lightweight, we will only run on a sample of 400 comments. Note that running over a larger set improves both the quality and coverage of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb6777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [c for c in comments if len(c['text'])<=1000]\n",
    "comments_2016 = [c for c in comments if c['year'] == '2016']\n",
    "sample_size = 400\n",
    "random.seed(0)\n",
    "comments_2016_sample = random.sample(comments_2016, sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916ebe73",
   "metadata": {},
   "source": [
    "*Key point analysis* is a novel and promising approach for summarization, with an important quantitative angle. This service summarizes a collection of comments on a given topic as a small set of key points. The salience of each key point is given by the number of its matching sentences in the given comments.\n",
    "\n",
    "Before running the *Key Point Analysis* service we first need to initialize our client. The clients print information using the logger and a suitable verbosity level should be set. The client object is configured with an API key. It should be  retrieved from the [Project Debater Early Access Program](https://early-access-program.debater.res.ibm.com/) site.  In the code bellow it is passed by the enviroment variable *DEBATER_API_KEY* (you may also modify the code and place the api-key directly).\n",
    "\n",
    "The *Key Point Analysis* service stores the data (and cached-results) in a *domain*. A user can create several domains, one for each dataset. Domains are only accessible to the user who created them.\n",
    "\n",
    "Full documentation of the *Key Point Analysis* service can be found [here](https://early-access-program.debater.res.ibm.com/docs/services/keypoints/keypoints_pydoc.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4582d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "KpAnalysisUtils.init_logger()\n",
    "api_key = os.environ['DEBATER_API_KEY']\n",
    "host = 'https://keypoint-matching-backend.debater.res.ibm.com'\n",
    "keypoints_client = KpAnalysisClient(api_key, host)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4b8dc",
   "metadata": {},
   "source": [
    "In order to run *Key Point Analysis*, do the following steps:\n",
    "\n",
    "### 1.2 Create a domain\n",
    "Create a domin using the **keypoints_client.create_domain(domain=domain, domain_params={})** method. Several params can be passed when creating a domain in the domain_params dictionary as described in the documentation. Leaving it empty gives us a good default behaviour. You can also use **KpAnalysisUtils.create_domain_ignore_exists(client=keypoints_client, domain=domain, domain_params={})** if you don't want an exception to be thrown if the domain already exists. Note that in such case the domain_params are not updated and are remained as they where before.\n",
    "\n",
    "Full documentation of the supported *domain_params* and how they affect the domain can be found [here](https://early-access-program.debater.res.ibm.com/docs/services/keypoints/keypoint_parameters_users.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4956e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:53:54,145 [INFO] keypoints_client.py 424: client calls service (post): https://keypoint-matching-backend.debater.res.ibm.com/domains\n",
      "2022-09-22 11:53:55,356 [INFO] keypoints_client.py 475: created domain: austin_demo with domain_params: {}\n",
      "2022-09-22 11:53:55,357 [INFO] keypoints_client.py 270: domain: austin_demo was created\n"
     ]
    }
   ],
   "source": [
    "domain = 'austin_demo'\n",
    "KpAnalysisUtils.create_domain_ignore_exists(client=keypoints_client, domain=domain, domain_params={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd618c78",
   "metadata": {},
   "source": [
    "Few domain related points:\n",
    "* We can always delete a domain we no longer need using: **KpAnalysisUtils.delete_domain_ignore_doesnt_exist(client=keypoints_client, domain=domain)**\n",
    "* Keep in mind that a domain has a state. It stores all comments that had beed uploaded into it and a cache with all calculations performed over this data.\n",
    "* If we want to restart and run over the domain from scratch (no comments and no cache), we can delete the domain and then re-create it or obviously use a different domain. Keep in mind that the cache is also cleared and consecutive runs will take longer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82c51cd",
   "metadata": {},
   "source": [
    "### 1.3 Upload comments into the domain\n",
    "Upload the comments into the domain using the **keypoints_client.upload_comments(domain=domain, comments_ids=comments_ids, comments_texts=comments_texts)** method. This method receives the domain, a list of comment_ids and a list of comment_texts. When uploading comments into a domain, the *Key Point Analysis* service splits the comments into sentences and runs a minor cleansing on the sentences. If you have domain-specific knowladge and want to split the comments into sentences yourself, you can upload comments that are already splitted into sentences and set the *dont_split* parameter to True (in the domain_params when creating the domain) and *Key Point Analysis* will use the provided sentences as is. \n",
    "\n",
    "Note that:\n",
    "* Comments_ids must be unique\n",
    "* The number of comments_ids must match the number comments_texts\n",
    "* Comments_texts must not be longer than 1000 characters\n",
    "* Uploading the same comment several times (same domain + comment_id, comment_text is ignored) is not a problem and the comment is only uploaded once (if the comment_text is different, it is NOT updated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4da5d650",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:53:55,373 [INFO] keypoints_client.py 497: uploading 400 comments in batches\n",
      "2022-09-22 11:53:55,377 [INFO] keypoints_client.py 424: client calls service (post): https://keypoint-matching-backend.debater.res.ibm.com/comments\n",
      "2022-09-22 11:53:56,297 [INFO] keypoints_client.py 511: uploaded 400 comments, out of 400\n"
     ]
    }
   ],
   "source": [
    "comments_texts = [comment['text'] for comment in comments_2016_sample]\n",
    "comments_ids = [comment['id'] for comment in comments_2016_sample]\n",
    "keypoints_client.upload_comments(domain=domain, comments_ids=comments_ids, comments_texts=comments_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183b1da7",
   "metadata": {},
   "source": [
    "### 1.4 Wait for the comments to be processed\n",
    "Comments that are uploaded to the domain are being processed. This takes some times and runs in an async manner. We can't run an analysis before this phase finishes and we need to wait till all comments in the domain are processed using the **keypoints_client.wait_till_all_comments_are_processed(domain=domain)** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220393ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:53:56,314 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/comments\n",
      "2022-09-22 11:53:56,908 [INFO] keypoints_client.py 523: domain: austin_demo, comments status: {'processed_comments': 0, 'processed_sentences': 0, 'pending_comments': 400}\n",
      "2022-09-22 11:54:06,914 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/comments\n",
      "2022-09-22 11:54:07,521 [INFO] keypoints_client.py 523: domain: austin_demo, comments status: {'processed_comments': 400, 'processed_sentences': 682, 'pending_comments': 0}\n"
     ]
    }
   ],
   "source": [
    "keypoints_client.wait_till_all_comments_are_processed(domain=domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da852b04",
   "metadata": {},
   "source": [
    "### 1.5 Start a Key Point Analysis job\n",
    "Start a *Key Point Analysis* job using the **future = keypoints_client.start_kp_analysis_job(domain=domain, run_params=run_params)** method. This method receives the domain and a *run_params*. The run_params is a dictionary with various parameters for customizing the job. Leaving it empty gives us a good default behaviour. The job runs in an async manner therefore the method returns a future object.\n",
    "\n",
    "Few additional options when running an analysis job:\n",
    "* The analysis is performed over all comments in the domain. If we need to run over a subset of the comments (split the data by different GEOs/users types/timeframes etc') we can pass a list of comments_ids to the comments_ids parameter and it will create an analysis using only the provided comments.\n",
    "* By default, key points are extracted automatically. When we want to provide key points and match all sentences to these key points we can do so by passing them to the keypoints parameter: **run_param['keypoints'] = [...]**. This enables a mode of work named human-in-the-loop where we first automatically extract key points, then we manually edit them (refine non-perfect key points, remove duplicated and add missing ones) and then run again, this time providing the edited keypoints as a given set of key points.\n",
    "* It is also possible to provide key points and let KPA add additional missing key points. To do so pass the key points to the keypoint_candidates parameter: **run_param['keypoint_candidates'] = [...]** (see section 4 for an elaborated example).\n",
    "* Full documentation of the supported *domain_params* and *run_params* and how they affect the analysis can be found [here](https://early-access-program.debater.res.ibm.com/docs/services/keypoints/keypoint_parameters_users.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "948bf751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:54:07,535 [INFO] keypoints_client.py 424: client calls service (post): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:54:08,197 [INFO] keypoints_client.py 579: started a kp analysis job - domain: austin_demo, run_params: {}, job_id: 632c22b0116742ef7549706b\n"
     ]
    }
   ],
   "source": [
    "future = keypoints_client.start_kp_analysis_job(domain=domain, run_params={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1e4414",
   "metadata": {},
   "source": [
    "### 1.6 Wait for the Key Point Analysis job to finish\n",
    "Use the returned future and wait till results are available using the **kpa_result = future.get_result()** method. The method waits for the job to finish and eventually returns the result. The result is a dictionary containing the key points (sorted descendingly according to number of matched sentences) and for each key point has a list of matched sentences (sorted descendingly according to their match score). An additional 'none' key point is added which holds all the sentences that don't match any key point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "455eee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:54:08,211 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:54:08,770 [INFO] keypoints_client.py 760: job_id 632c22b0116742ef7549706b is pending\n",
      "2022-09-22 11:54:38,778 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:54:39,382 [INFO] keypoints_client.py 764: job_id 632c22b0116742ef7549706b is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 0, 'total_batches': 20, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |--------------------------------------------------| 0.0% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:55:09,392 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:55:09,983 [INFO] keypoints_client.py 764: job_id 632c22b0116742ef7549706b is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 5, 'total_batches': 20, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |████████████--------------------------------------| 25.0% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:55:39,991 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:55:40,586 [INFO] keypoints_client.py 764: job_id 632c22b0116742ef7549706b is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 18, 'total_batches': 20, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |█████████████████████████████████████████████-----| 90.0% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:56:10,590 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:56:11,997 [INFO] keypoints_client.py 767: job_id 632c22b0116742ef7549706b is done, returning result\n"
     ]
    }
   ],
   "source": [
    "kpa_result_2016 = future.get_result(high_verbosity=True, polling_timout_secs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b3a24",
   "metadata": {},
   "source": [
    "Let's print the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6af7396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016 Random sample coverage: 42.57\n",
      "2016 Random sample key points:\n",
      "84 - Improvement on traffic problem.\n",
      "\t- Fix the traffic problems, forget bikes and add more lanes.\n",
      "\t- FIX THE TRAFFIC SITUATION MOPAC.\n",
      "60 - Improve affordable housing/living.\n",
      "\t- BUILD MORE AFFORDABLY HOUSING\n",
      "\t- AFFORDABLE HOUSING FOR LOW INCOME & TRAFFIC\n",
      "50 - Develop public transportation network.\n",
      "\t- DEVELOP REALISTIC PLAN FOR PUBLIC TRANSPORTATION.\n",
      "\t- affordable housing in key and public transportation to reduce the number of cars on the\n",
      "\t  roads\n",
      "26 - COST OF UTILITIES IS VERY HIGH\n",
      "\t- Utilities, particularly water, is too high.\n",
      "\t- Rest is too expensive, cost of living too high.\n",
      "15 - City wide planning pertaining to infrastructure.\n",
      "\t- Plan on more roads that run east and west of the city, between ih35 and mopac\n",
      "\t- Traffic all facets-planning, congestion, enforcement\n",
      "12 - The highways need a major overhaul.\n",
      "\t- Please improve the roadways.\n",
      "\t- Fix the darn roads!\n",
      "9 - DEVELOPMENT SHOULD NOT DISPLACE LOW INCOME FAMILIES.\n",
      "\t- New construction and existing corporations should relieve tax burden so that low income\n",
      "\t  families are not forced out!\n",
      "\t- TOLL ROADS DISCRIMINATE AGAINST LOW INCOME PEOPLE.\n",
      "9 - Streamline the residential permitting process.\n",
      "\t- Have permits for new commercial build outs be processed faster.\n",
      "\t- FIX PERMITS AND ZONING REQUIREMENTS.\n",
      "7 - Attract a most diverse population to Austin\n",
      "\t- This question should be on the tip of all the city staff's tongues How can we make\n",
      "\t  Austin a desirable city for people of all ethnicities?\n",
      "\t- Affordable housing is essential to keep Austin diverse, welcoming, and growing in the\n",
      "\t  ways that reflect the progressive ideals of this city and the future generations.\n",
      "6 - Stop the gentrification.\n",
      "\t- Don't let Austin become Houston with overdevelopment.\n",
      "\t- Stop turning Austin into California, Portland, Seattle.\n"
     ]
    }
   ],
   "source": [
    "from austin_utils import print_results\n",
    "print_results(kpa_result_2016, n_sentences_per_kp=2, title='2016 Random sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74421ee6",
   "metadata": {},
   "source": [
    "We can also save the results to file. This creates two files, one with the key points and all matched sentences and another summary file with only the key points and their saliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f5ed2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:56:12,024 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_kpa_results_kps_summary.csv\n",
      "2022-09-22 11:56:12,027 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_kpa_results.csv\n"
     ]
    }
   ],
   "source": [
    "KpAnalysisUtils.write_result_to_csv(kpa_result_2016, 'austin_survey_2016_kpa_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5a5ab0",
   "metadata": {},
   "source": [
    "It is always possible to cancel a pending/running job in the following way:\n",
    "* **keypoints_client.cancel_kp_extraction_job(\\<Job Id\\>)**\n",
    "\n",
    "Job Id can be found: \n",
    "1. It's printed when a job is started \n",
    "2. From the future object: **future.get_job_id()**\n",
    "3. From user report: **keypoints_client.get_full_report()** (see bellow)\n",
    "\n",
    "It is also possibe to stop all jobs in a domain, or even all jobs in all domains (might be simpler since there is no need of the job_id):\n",
    "* **keypoints_client.cancel_all_extraction_jobs_for_domain(domain)**\n",
    "* **keypoints_client.cancel_all_extraction_jobs_all_domains()**\n",
    "\n",
    "Please cancel long jobs if the results are no longer needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1adffd",
   "metadata": {},
   "source": [
    "### 1.7 Modify the run_params and increase coverage\n",
    "Each domain has a cache that stores all intermediate results that are calculated during the analysis. Therefore modifing the run_params and running another analysis runs much faster and all intersecting intermediate results are retreived from cache. \n",
    "\n",
    "Let's run again, but now reduce the **clustering_threshold** and **mapping_threshold**. The **clustering_threshold** is used for the key points selection (choose higher values for more fine-grained key points, and lower for more distinct key points). The **mapping_threshold** is used when mapping all sentences to the final key points (a lower threshold leads to a higher coverage with the risk of a lower precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "199d24fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:56:12,033 [INFO] keypoints_client.py 424: client calls service (post): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:56:12,621 [INFO] keypoints_client.py 579: started a kp analysis job - domain: austin_demo, run_params: {'clustering_threshold': 0.95, 'mapping_threshold': 0.95}, job_id: 632c232c116742ef7549706e\n",
      "2022-09-22 11:56:12,624 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:56:13,164 [INFO] keypoints_client.py 760: job_id 632c232c116742ef7549706e is pending\n",
      "2022-09-22 11:56:43,170 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:56:44,523 [INFO] keypoints_client.py 767: job_id 632c232c116742ef7549706e is done, returning result\n",
      "2022-09-22 11:56:44,528 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_kpa_results_kps_summary.csv\n",
      "2022-09-22 11:56:44,538 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_kpa_results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample coverage: 46.86\n",
      "Random sample key points:\n",
      "96 - Improvement on traffic problem.\n",
      "\t- Fix the traffic problems, forget bikes and add more lanes.\n",
      "\t- FIX THE TRAFFIC SITUATION MOPAC.\n",
      "64 - Improve affordable housing/living.\n",
      "\t- BUILD MORE AFFORDABLY HOUSING\n",
      "\t- AFFORDABLE HOUSING FOR LOW INCOME & TRAFFIC\n",
      "52 - Develop public transportation network.\n",
      "\t- DEVELOP REALISTIC PLAN FOR PUBLIC TRANSPORTATION.\n",
      "\t- affordable housing in key and public transportation to reduce the number of cars on the\n",
      "\t  roads\n",
      "35 - COST OF UTILITIES IS VERY HIGH\n",
      "\t- Utilities, particularly water, is too high.\n",
      "\t- Rest is too expensive, cost of living too high.\n",
      "15 - TO HAVE BETTER PLANNING FOR CITY GROWTH.\n",
      "\t- Plan out the growth for Austin as the city grows.\n",
      "\t- Should have been better prepared for the city growth like Houston, San Antonio, Dallas.\n",
      "11 - Streamline the residential permitting process.\n",
      "\t- Have permits for new commercial build outs be processed faster.\n",
      "\t- FIX PERMITS AND ZONING REQUIREMENTS.\n",
      "10 - DEVELOPMENT SHOULD NOT DISPLACE LOW INCOME FAMILIES.\n",
      "\t- New construction and existing corporations should relieve tax burden so that low income\n",
      "\t  families are not forced out!\n",
      "\t- TOLL ROADS DISCRIMINATE AGAINST LOW INCOME PEOPLE.\n",
      "9 - PLEASE MAKE THIS CITY MORE BIKE FRIENDLY.\n",
      "\t- AND PLEASE GIVE US SAFE BIKE LANES THAT ARE PHYSICALLY SEPARATED FROM CARS - THIS COULD\n",
      "\t  BE A TOTAL BIKING CITY YEAR ROUND.\n",
      "\t- Make / preserve city policies that reflect kindness to animals, whether they be strays\n",
      "\t  or the deer that reside in some of our neighborhoods.\n",
      "8 - Stop the gentrification.\n",
      "\t- Don't let Austin become Houston with overdevelopment.\n",
      "\t- Stop turning Austin into California, Portland, Seattle.\n",
      "6 - Attract a most diverse population to Austin\n",
      "\t- This question should be on the tip of all the city staff's tongues How can we make\n",
      "\t  Austin a desirable city for people of all ethnicities?\n",
      "\t- Affordable housing is essential to keep Austin diverse, welcoming, and growing in the\n",
      "\t  ways that reflect the progressive ideals of this city and the future generations.\n"
     ]
    }
   ],
   "source": [
    "run_params = {'clustering_threshold': 0.95, 'mapping_threshold': 0.95}\n",
    "future = keypoints_client.start_kp_analysis_job(domain=domain, run_params=run_params)\n",
    "kpa_result_2016 = future.get_result(high_verbosity=True, polling_timout_secs=30)\n",
    "KpAnalysisUtils.write_result_to_csv(kpa_result_2016, 'austin_survey_2016_kpa_results.csv')\n",
    "print_results(kpa_result_2016, n_sentences_per_kp=2, title='Random sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61557e9",
   "metadata": {},
   "source": [
    "By reducing the thresholds, the coverage was increased from 42.5% to 46.8%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523a7d0",
   "metadata": {},
   "source": [
    "### 1.8 User Report\n",
    "When we want to see what domains we have, maybe delete old ones that are not needed, see past and present analysis jobs, perhaps take their job_id and fetch their result \n",
    "(via **KpAnalysisTaskFuture(keypoints_client, \\<job_id\\>).get_result()** ), \n",
    "we can get a report with all the needed information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212b4c29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = keypoints_client.get_full_report()\n",
    "KpAnalysisUtils.print_report(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6d46c",
   "metadata": {},
   "source": [
    "## 2. Mapping sentences to multiple key points, and creating a Key-Points-Graphs\n",
    "By default, each sentence is mapped to one key point at most (the key point with the highest match-score, above the **mapping_threshold**). We can run again and ask KPA to map each sentence to all key points with a match-score above the **mapping_threshold**, by adding the **sentence_to_multiple_kps** parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b677b860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:56:45,673 [INFO] keypoints_client.py 424: client calls service (post): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:56:46,317 [INFO] keypoints_client.py 579: started a kp analysis job - domain: austin_demo, run_params: {'clustering_threshold': 0.95, 'mapping_threshold': 0.95, 'sentence_to_multiple_kps': True}, job_id: 632c234e116742ef75497071\n",
      "2022-09-22 11:56:46,320 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:56:46,863 [INFO] keypoints_client.py 760: job_id 632c234e116742ef75497071 is pending\n",
      "2022-09-22 11:57:16,871 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:57:18,309 [INFO] keypoints_client.py 767: job_id 632c234e116742ef75497071 is done, returning result\n"
     ]
    }
   ],
   "source": [
    "run_params = {'clustering_threshold': 0.95, 'mapping_threshold': 0.95, \n",
    "              'sentence_to_multiple_kps': True}\n",
    "future = keypoints_client.start_kp_analysis_job(domain=domain, run_params=run_params)\n",
    "kpa_analysis_2016_job_id = future.get_job_id() # saving the job_id for a following section\n",
    "kpa_result_multiple_kps = future.get_result(high_verbosity=True, polling_timout_secs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb6a89b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample coverage: 54.43\n",
      "Random sample key points:\n",
      "115 - Improvement on traffic problem.\n",
      "\t- Fix the traffic problems, forget bikes and add more lanes.\n",
      "\t- FIX THE TRAFFIC SITUATION MOPAC.\n",
      "92 - Work on making Austin affordable again.\n",
      "\t- Should be able to purchase a 3bd 2ba for under 300K in Austin.\n",
      "\t- Make Austin affordable again for hard working families\n",
      "72 - Develop public transportation network.\n",
      "\t- DEVELOP REALISTIC PLAN FOR PUBLIC TRANSPORTATION.\n",
      "\t- affordable housing in key and public transportation to reduce the number of cars on the\n",
      "\t  roads\n",
      "33 - Utilities, particularly water, is too high.\n",
      "\t- Traffic and high utility bills are a problem for me\n",
      "\t- COST OF UTILITIES IS VERY HIGH\n",
      "29 - PLEASE MAKE THIS CITY MORE BIKE FRIENDLY.\n",
      "\t- AND PLEASE GIVE US SAFE BIKE LANES THAT ARE PHYSICALLY SEPARATED FROM CARS - THIS COULD\n",
      "\t  BE A TOTAL BIKING CITY YEAR ROUND.\n",
      "\t- Contributing to the traffic congestion going into the city.\n",
      "23 - make every effort to eradicate poverty\n",
      "\t- PROTECT EAST AUSTIN AND THE POOR\n",
      "\t- DEVELOPMENT SHOULD NOT DISPLACE LOW INCOME FAMILIES.\n",
      "19 - Improve the auto circulation.\n",
      "\t- Traffic signals need to be synchronized to provide for better flow of traffic around the\n",
      "\t  city.\n",
      "\t- This city needs more motor vehicle traffic lanes!!\n",
      "18 - TO HAVE BETTER PLANNING FOR CITY GROWTH.\n",
      "\t- Plan out the growth for Austin as the city grows.\n",
      "\t- Should have been better prepared for the city growth like Houston, San Antonio, Dallas.\n",
      "12 - Stop the gentrification.\n",
      "\t- Don't let Austin become Houston with overdevelopment.\n",
      "\t- Stop turning Austin into California, Portland, Seattle.\n",
      "11 - Streamline the residential permitting process.\n",
      "\t- Have permits for new commercial build outs be processed faster.\n",
      "\t- FIX PERMITS AND ZONING REQUIREMENTS.\n"
     ]
    }
   ],
   "source": [
    "print_results(kpa_result_multiple_kps, n_sentences_per_kp=2, title='Random sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d94bd",
   "metadata": {},
   "source": [
    "Now that sentences are mapped to multiple key points, it is possible to create a *key points graph* by first saving the results as before, then translating the results file into a graph-data json file, then load this json file in our demo graph visualization, available at: [key points graph demo](https://keypoint-matching-ui.ris2-debater-event.us-east.containers.appdomain.cloud/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b9c2614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:57:18,325 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_multiple_kpa_results_kps_summary.csv\n",
      "2022-09-22 11:57:18,328 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_multiple_kpa_results.csv\n",
      "2022-09-22 11:57:18,333 [INFO] keypoints_client.py 355: Creating key points graph data-file for results file: austin_survey_2016_multiple_kpa_results.csv\n",
      "2022-09-22 11:57:18,334 [INFO] keypoints_client.py 330: reading file: austin_survey_2016_multiple_kpa_results.csv\n",
      "2022-09-22 11:57:18,352 [INFO] keypoints_client.py 388: saving graph in file: austin_survey_2016_multiple_kpa_results_graph_data.json\n",
      "2022-09-22 11:57:18,352 [INFO] keypoints_client.py 389: saving graph in file: austin_survey_2016_multiple_kpa_results_graph_data.json\n"
     ]
    }
   ],
   "source": [
    "KpAnalysisUtils.write_result_to_csv(kpa_result_multiple_kps, 'austin_survey_2016_multiple_kpa_results.csv')\n",
    "KpAnalysisUtils.create_graph_data_file_for_ui('austin_survey_2016_multiple_kpa_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818fd69a",
   "metadata": {},
   "source": [
    "You can now go to: [key points graph demo](https://keypoint-matching-ui.ris2-debater-event.us-east.containers.appdomain.cloud/) and load the graph's data file **austin_survey_2016_multiple_kpa_results_graph_data.json** to the ui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff92aa",
   "metadata": {},
   "source": [
    "## 3. Run *Key Point Analysis* incrementally\n",
    "### 3.1 Run *Key Point Analysis* incrementally on new data (data from 2016 + 2017)\n",
    "A year passed, and we collect additional data (data from 2017). We can now upload the 2017 data to the same domain (austin_demo) and have both 2016 and 2017 data in one domain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a5f9111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:57:18,358 [INFO] keypoints_client.py 497: uploading 400 comments in batches\n",
      "2022-09-22 11:57:18,358 [INFO] keypoints_client.py 424: client calls service (post): https://keypoint-matching-backend.debater.res.ibm.com/comments\n",
      "2022-09-22 11:57:19,233 [INFO] keypoints_client.py 511: uploaded 400 comments, out of 400\n",
      "2022-09-22 11:57:19,234 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/comments\n",
      "2022-09-22 11:57:19,862 [INFO] keypoints_client.py 523: domain: austin_demo, comments status: {'processed_comments': 400, 'processed_sentences': 682, 'pending_comments': 400}\n",
      "2022-09-22 11:57:29,866 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/comments\n",
      "2022-09-22 11:57:30,508 [INFO] keypoints_client.py 523: domain: austin_demo, comments status: {'processed_comments': 800, 'processed_sentences': 1440, 'pending_comments': 0}\n"
     ]
    }
   ],
   "source": [
    "comments_2017 = [c for c in comments if c['year'] == '2017']\n",
    "comments_2017_sample = random.sample(comments_2017, sample_size)\n",
    "\n",
    "domain = 'austin_demo'\n",
    "comments_texts = [comment['text'] for comment in comments_2017_sample]\n",
    "comments_ids = [comment['id'] for comment in comments_2017_sample]\n",
    "keypoints_client.upload_comments(domain=domain, comments_ids=comments_ids, comments_texts=comments_texts)\n",
    "keypoints_client.wait_till_all_comments_are_processed(domain=domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cdd33f",
   "metadata": {},
   "source": [
    "We can now run a new analysis over all the data in the domain, as we did before, and automatically extract new key points. We can assume that some will be identical to the key points extracted on the 2016 data, some will be similar and some key points will be new.\n",
    "\n",
    "A better option is to run a new analysis but provide the keypoints from the 2016 analysis and let *Key Point Analysis* add new key points of 2017 data if there are such. One benefit of this approach is that the new result will mostly use 2016 key point and we will be able to compare between them, see what changed, what improved and what not. Another major benefit for this approach is run-time. 2016 data was already analyzed with these key points and since we have a cache in place much of the computation can be avoided. The 2016 key points can be provided via the: **run_param['keypoint_candidates'] = [...]** parameter, passing a list of strings, or we can use: **run_param['keypoint_candidates_by_job_id'] = <job_id>** and provide the job_id of an analysis job. KPA will take the key points from the job's result automatically. We will use this parameter and provide the *kpa_analysis_2016_job_id* we saved in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1b4a120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:57:30,524 [INFO] keypoints_client.py 424: client calls service (post): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:57:31,279 [INFO] keypoints_client.py 579: started a kp analysis job - domain: austin_demo, run_params: {'clustering_threshold': 0.95, 'mapping_threshold': 0.95, 'sentence_to_multiple_kps': True, 'keypoint_candidates_by_job_id': '632c234e116742ef75497071'}, job_id: 632c237b116742ef75497075\n",
      "2022-09-22 11:57:31,282 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:57:31,813 [INFO] keypoints_client.py 760: job_id 632c237b116742ef75497075 is pending\n",
      "2022-09-22 11:58:01,816 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:58:02,418 [INFO] keypoints_client.py 764: job_id 632c237b116742ef75497075 is running, progress: {'total_stages': 3, 'stage_0': {'inferred_batches': 0, 'total_batches': 1, 'batch_size': 2000}}\n",
      "2022-09-22 11:58:32,425 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:58:33,089 [INFO] keypoints_client.py 764: job_id 632c237b116742ef75497075 is running, progress: {'total_stages': 3, 'stage_0': {'inferred_batches': 1, 'total_batches': 1, 'batch_size': 2000}, 'stage_1': {'inferred_batches': 0, 'total_batches': 28, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/3: |--------------------------------------------------| 0.0% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:59:03,096 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:59:03,689 [INFO] keypoints_client.py 764: job_id 632c237b116742ef75497075 is running, progress: {'total_stages': 3, 'stage_0': {'inferred_batches': 1, 'total_batches': 1, 'batch_size': 2000}, 'stage_1': {'inferred_batches': 0, 'total_batches': 28, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/3: |--------------------------------------------------| 0.0% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 11:59:33,694 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 11:59:34,303 [INFO] keypoints_client.py 764: job_id 632c237b116742ef75497075 is running, progress: {'total_stages': 3, 'stage_0': {'inferred_batches': 1, 'total_batches': 1, 'batch_size': 2000}, 'stage_1': {'inferred_batches': 4, 'total_batches': 28, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/3: |███████-------------------------------------------| 14.3% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:00:04,296 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:00:04,925 [INFO] keypoints_client.py 764: job_id 632c237b116742ef75497075 is running, progress: {'total_stages': 3, 'stage_0': {'inferred_batches': 1, 'total_batches': 1, 'batch_size': 2000}, 'stage_1': {'inferred_batches': 19, 'total_batches': 28, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/3: |█████████████████████████████████-----------------| 67.9% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:00:34,926 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:00:35,551 [INFO] keypoints_client.py 764: job_id 632c237b116742ef75497075 is running, progress: {'total_stages': 3, 'stage_0': {'inferred_batches': 1, 'total_batches': 1, 'batch_size': 2000}, 'stage_1': {'inferred_batches': 24, 'total_batches': 28, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/3: |██████████████████████████████████████████--------| 85.7% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:01:05,555 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:01:07,304 [INFO] keypoints_client.py 767: job_id 632c237b116742ef75497075 is done, returning result\n"
     ]
    }
   ],
   "source": [
    "run_params = {'clustering_threshold': 0.95, 'mapping_threshold': 0.95, 'sentence_to_multiple_kps': True,\n",
    "              'keypoint_candidates_by_job_id': kpa_analysis_2016_job_id}\n",
    "future = keypoints_client.start_kp_analysis_job(domain=domain, run_params=run_params)\n",
    "kpa_result_2016_2017 = future.get_result(high_verbosity=True, polling_timout_secs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5a0af0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:01:07,317 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_2017_kpa_results_kps_summary.csv\n",
      "2022-09-22 12:01:07,325 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_2017_kpa_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key point</th>\n",
       "      <th>2016_n_sents</th>\n",
       "      <th>2016_percent</th>\n",
       "      <th>2016 + 2017_n_sents</th>\n",
       "      <th>2016 + 2017_percent</th>\n",
       "      <th>change_n_sents</th>\n",
       "      <th>change_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Improvement on traffic problem.</td>\n",
       "      <td>96</td>\n",
       "      <td>14.70%</td>\n",
       "      <td>210</td>\n",
       "      <td>11.76%</td>\n",
       "      <td>114</td>\n",
       "      <td>-2.94%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Develop public transportation network.</td>\n",
       "      <td>52</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>112</td>\n",
       "      <td>6.27%</td>\n",
       "      <td>60</td>\n",
       "      <td>-1.69%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TO HAVE BETTER PLANNING FOR CITY GROWTH.</td>\n",
       "      <td>15</td>\n",
       "      <td>2.30%</td>\n",
       "      <td>30</td>\n",
       "      <td>1.68%</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Streamline the residential permitting process.</td>\n",
       "      <td>11</td>\n",
       "      <td>1.68%</td>\n",
       "      <td>19</td>\n",
       "      <td>1.06%</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.62%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PLEASE MAKE THIS CITY MORE BIKE FRIENDLY.</td>\n",
       "      <td>9</td>\n",
       "      <td>1.38%</td>\n",
       "      <td>64</td>\n",
       "      <td>3.58%</td>\n",
       "      <td>55</td>\n",
       "      <td>2.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop the gentrification.</td>\n",
       "      <td>8</td>\n",
       "      <td>1.23%</td>\n",
       "      <td>22</td>\n",
       "      <td>1.23%</td>\n",
       "      <td>14</td>\n",
       "      <td>0.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Improve affordable housing/living.</td>\n",
       "      <td>64</td>\n",
       "      <td>9.80%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COST OF UTILITIES IS VERY HIGH</td>\n",
       "      <td>35</td>\n",
       "      <td>5.36%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DEVELOPMENT SHOULD NOT DISPLACE LOW INCOME FAM...</td>\n",
       "      <td>10</td>\n",
       "      <td>1.53%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Attract a most diverse population to Austin</td>\n",
       "      <td>6</td>\n",
       "      <td>0.92%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Work on making Austin affordable again.</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>172</td>\n",
       "      <td>9.63%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PROPERTY TAXES ARE TOO HIGH!</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>96</td>\n",
       "      <td>5.38%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Utilities, particularly water, is too high.</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>59</td>\n",
       "      <td>3.30%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Speed up highway construction.</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>50</td>\n",
       "      <td>2.80%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>We have a HUGE homeless problem.</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>44</td>\n",
       "      <td>2.46%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Promote polices like public housing</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>40</td>\n",
       "      <td>2.24%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>make every effort to eradicate poverty</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>33</td>\n",
       "      <td>1.85%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Improve the auto circulation.</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>25</td>\n",
       "      <td>1.40%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Continue to support diversity</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>23</td>\n",
       "      <td>1.29%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>OBEY NATIONAL &amp; STATE LAWS.</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>23</td>\n",
       "      <td>1.29%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CUT BUILDING REGULATIONS.</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>20</td>\n",
       "      <td>1.12%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Slow down development</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>19</td>\n",
       "      <td>1.06%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>WEST CAMPUS DEVELOPMENT IS OUT OF CONTROL.</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>15</td>\n",
       "      <td>0.84%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>QUALITY OF LIFE FOR RETIREES</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>13</td>\n",
       "      <td>0.73%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            key point 2016_n_sents  \\\n",
       "0                     Improvement on traffic problem.           96   \n",
       "1              Develop public transportation network.           52   \n",
       "2            TO HAVE BETTER PLANNING FOR CITY GROWTH.           15   \n",
       "3      Streamline the residential permitting process.           11   \n",
       "4           PLEASE MAKE THIS CITY MORE BIKE FRIENDLY.            9   \n",
       "5                            Stop the gentrification.            8   \n",
       "6                  Improve affordable housing/living.           64   \n",
       "7                      COST OF UTILITIES IS VERY HIGH           35   \n",
       "8   DEVELOPMENT SHOULD NOT DISPLACE LOW INCOME FAM...           10   \n",
       "9         Attract a most diverse population to Austin            6   \n",
       "10            Work on making Austin affordable again.          ---   \n",
       "11                       PROPERTY TAXES ARE TOO HIGH!          ---   \n",
       "12        Utilities, particularly water, is too high.          ---   \n",
       "13                     Speed up highway construction.          ---   \n",
       "14                   We have a HUGE homeless problem.          ---   \n",
       "15                Promote polices like public housing          ---   \n",
       "16             make every effort to eradicate poverty          ---   \n",
       "17                      Improve the auto circulation.          ---   \n",
       "18                      Continue to support diversity          ---   \n",
       "19                        OBEY NATIONAL & STATE LAWS.          ---   \n",
       "20                          CUT BUILDING REGULATIONS.          ---   \n",
       "21                              Slow down development          ---   \n",
       "22         WEST CAMPUS DEVELOPMENT IS OUT OF CONTROL.          ---   \n",
       "23                       QUALITY OF LIFE FOR RETIREES          ---   \n",
       "\n",
       "   2016_percent 2016 + 2017_n_sents 2016 + 2017_percent change_n_sents  \\\n",
       "0        14.70%                 210              11.76%            114   \n",
       "1         7.96%                 112               6.27%             60   \n",
       "2         2.30%                  30               1.68%             15   \n",
       "3         1.68%                  19               1.06%              8   \n",
       "4         1.38%                  64               3.58%             55   \n",
       "5         1.23%                  22               1.23%             14   \n",
       "6         9.80%                 ---                 ---            ---   \n",
       "7         5.36%                 ---                 ---            ---   \n",
       "8         1.53%                 ---                 ---            ---   \n",
       "9         0.92%                 ---                 ---            ---   \n",
       "10          ---                 172               9.63%            ---   \n",
       "11          ---                  96               5.38%            ---   \n",
       "12          ---                  59               3.30%            ---   \n",
       "13          ---                  50               2.80%            ---   \n",
       "14          ---                  44               2.46%            ---   \n",
       "15          ---                  40               2.24%            ---   \n",
       "16          ---                  33               1.85%            ---   \n",
       "17          ---                  25               1.40%            ---   \n",
       "18          ---                  23               1.29%            ---   \n",
       "19          ---                  23               1.29%            ---   \n",
       "20          ---                  20               1.12%            ---   \n",
       "21          ---                  19               1.06%            ---   \n",
       "22          ---                  15               0.84%            ---   \n",
       "23          ---                  13               0.73%            ---   \n",
       "\n",
       "   change_percent  \n",
       "0          -2.94%  \n",
       "1          -1.69%  \n",
       "2          -0.62%  \n",
       "3          -0.62%  \n",
       "4           2.21%  \n",
       "5           0.01%  \n",
       "6             ---  \n",
       "7             ---  \n",
       "8             ---  \n",
       "9             ---  \n",
       "10            ---  \n",
       "11            ---  \n",
       "12            ---  \n",
       "13            ---  \n",
       "14            ---  \n",
       "15            ---  \n",
       "16            ---  \n",
       "17            ---  \n",
       "18            ---  \n",
       "19            ---  \n",
       "20            ---  \n",
       "21            ---  \n",
       "22            ---  \n",
       "23            ---  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KpAnalysisUtils.write_result_to_csv(kpa_result_2016_2017, 'austin_survey_2016_2017_kpa_results.csv')\n",
    "from austin_utils import compare_results\n",
    "comparison_df = compare_results(kpa_result_2016, '2016', kpa_result_2016_2017, '2016 + 2017')\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8412e2",
   "metadata": {},
   "source": [
    "### 3.2 Run *Key Point Analysis* incrementaly on new data (2017 independantly)\n",
    "Using the **comments_ids** parameter in **start_kp_analysis_job** method, we can run over a subset of the comments in the domain. Let's do that and run an analysis over 2017 comments independantly. We will provide the key points from 2016 since we want to able to compare between them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d574a490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:01:07,353 [INFO] keypoints_client.py 424: client calls service (post): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:01:08,490 [INFO] keypoints_client.py 579: started a kp analysis job - domain: austin_demo, run_params: {'clustering_threshold': 0.95, 'mapping_threshold': 0.95, 'sentence_to_multiple_kps': True, 'keypoint_candidates_by_job_id': '632c234e116742ef75497071'}, job_id: 632c2454116742ef7549707a\n",
      "2022-09-22 12:01:08,493 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:01:09,093 [INFO] keypoints_client.py 760: job_id 632c2454116742ef7549707a is pending\n",
      "2022-09-22 12:01:39,101 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:01:39,723 [INFO] keypoints_client.py 764: job_id 632c2454116742ef7549707a is running, progress: {'total_stages': 3, 'stage_0': {'inferred_batches': 1, 'total_batches': 1, 'batch_size': 2000}, 'stage_1': {'inferred_batches': 0, 'total_batches': 1, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/3: |--------------------------------------------------| 0.0% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:02:09,726 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:02:11,195 [INFO] keypoints_client.py 767: job_id 632c2454116742ef7549707a is done, returning result\n",
      "2022-09-22 12:02:11,202 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2017_kpa_results_kps_summary.csv\n",
      "2022-09-22 12:02:11,210 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2017_kpa_results.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key point</th>\n",
       "      <th>2016_n_sents</th>\n",
       "      <th>2016_percent</th>\n",
       "      <th>2017_n_sents</th>\n",
       "      <th>2017_percent</th>\n",
       "      <th>change_n_sents</th>\n",
       "      <th>change_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Improvement on traffic problem.</td>\n",
       "      <td>96</td>\n",
       "      <td>14.70%</td>\n",
       "      <td>95</td>\n",
       "      <td>11.28%</td>\n",
       "      <td>-1</td>\n",
       "      <td>-3.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Develop public transportation network.</td>\n",
       "      <td>52</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>40</td>\n",
       "      <td>4.75%</td>\n",
       "      <td>-12</td>\n",
       "      <td>-3.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TO HAVE BETTER PLANNING FOR CITY GROWTH.</td>\n",
       "      <td>15</td>\n",
       "      <td>2.30%</td>\n",
       "      <td>12</td>\n",
       "      <td>1.43%</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PLEASE MAKE THIS CITY MORE BIKE FRIENDLY.</td>\n",
       "      <td>9</td>\n",
       "      <td>1.38%</td>\n",
       "      <td>35</td>\n",
       "      <td>4.16%</td>\n",
       "      <td>26</td>\n",
       "      <td>2.78%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Improve affordable housing/living.</td>\n",
       "      <td>64</td>\n",
       "      <td>9.80%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COST OF UTILITIES IS VERY HIGH</td>\n",
       "      <td>35</td>\n",
       "      <td>5.36%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Streamline the residential permitting process.</td>\n",
       "      <td>11</td>\n",
       "      <td>1.68%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DEVELOPMENT SHOULD NOT DISPLACE LOW INCOME FAM...</td>\n",
       "      <td>10</td>\n",
       "      <td>1.53%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stop the gentrification.</td>\n",
       "      <td>8</td>\n",
       "      <td>1.23%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Attract a most diverse population to Austin</td>\n",
       "      <td>6</td>\n",
       "      <td>0.92%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Work on making Austin affordable again.</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>80</td>\n",
       "      <td>9.50%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TAXES ARE TOO HIGH</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>60</td>\n",
       "      <td>7.13%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>We have a HUGE homeless problem.</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>27</td>\n",
       "      <td>3.21%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Speed up highway construction.</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>25</td>\n",
       "      <td>2.97%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Promote polices like public housing</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>19</td>\n",
       "      <td>2.26%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OBEY NATIONAL &amp; STATE LAWS.</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>17</td>\n",
       "      <td>2.02%</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            key point 2016_n_sents  \\\n",
       "0                     Improvement on traffic problem.           96   \n",
       "1              Develop public transportation network.           52   \n",
       "2            TO HAVE BETTER PLANNING FOR CITY GROWTH.           15   \n",
       "3           PLEASE MAKE THIS CITY MORE BIKE FRIENDLY.            9   \n",
       "4                  Improve affordable housing/living.           64   \n",
       "5                      COST OF UTILITIES IS VERY HIGH           35   \n",
       "6      Streamline the residential permitting process.           11   \n",
       "7   DEVELOPMENT SHOULD NOT DISPLACE LOW INCOME FAM...           10   \n",
       "8                            Stop the gentrification.            8   \n",
       "9         Attract a most diverse population to Austin            6   \n",
       "10            Work on making Austin affordable again.          ---   \n",
       "11                                 TAXES ARE TOO HIGH          ---   \n",
       "12                   We have a HUGE homeless problem.          ---   \n",
       "13                     Speed up highway construction.          ---   \n",
       "14                Promote polices like public housing          ---   \n",
       "15                        OBEY NATIONAL & STATE LAWS.          ---   \n",
       "\n",
       "   2016_percent 2017_n_sents 2017_percent change_n_sents change_percent  \n",
       "0        14.70%           95       11.28%             -1         -3.42%  \n",
       "1         7.96%           40        4.75%            -12         -3.21%  \n",
       "2         2.30%           12        1.43%             -3         -0.87%  \n",
       "3         1.38%           35        4.16%             26          2.78%  \n",
       "4         9.80%          ---          ---            ---            ---  \n",
       "5         5.36%          ---          ---            ---            ---  \n",
       "6         1.68%          ---          ---            ---            ---  \n",
       "7         1.53%          ---          ---            ---            ---  \n",
       "8         1.23%          ---          ---            ---            ---  \n",
       "9         0.92%          ---          ---            ---            ---  \n",
       "10          ---           80        9.50%            ---            ---  \n",
       "11          ---           60        7.13%            ---            ---  \n",
       "12          ---           27        3.21%            ---            ---  \n",
       "13          ---           25        2.97%            ---            ---  \n",
       "14          ---           19        2.26%            ---            ---  \n",
       "15          ---           17        2.02%            ---            ---  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments_ids = [comment['id'] for comment in comments_2017_sample]\n",
    "run_params = {'clustering_threshold': 0.95, 'mapping_threshold': 0.95, 'sentence_to_multiple_kps': True,\n",
    "              'keypoint_candidates_by_job_id': kpa_analysis_2016_job_id}\n",
    "future = keypoints_client.start_kp_analysis_job(comments_ids=comments_ids, domain=domain, run_params=run_params)\n",
    "kpa_result_2017 = future.get_result(high_verbosity=True, polling_timout_secs=30)\n",
    "\n",
    "KpAnalysisUtils.write_result_to_csv(kpa_result_2017, 'austin_survey_2017_kpa_results.csv')\n",
    "comparison_df = compare_results(kpa_result_2016, '2016', kpa_result_2017, '2017')\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa5b2f6",
   "metadata": {},
   "source": [
    "Running over subsets of the data in the domain enable us to compare results between them (subsets can be data from different GEOs, different organizations, different users (e.g. promoters/detractors) etc')."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de996c7b",
   "metadata": {},
   "source": [
    "## 4. Run *Key Point Analysis* on each stance separately\n",
    "In many use-cases (surveys, customer feedback, etc') the comments have positive and/or negative stance, and it is usful to create a KPA analysis on each stance seperatly. Most stance detection models don't perfome too well on survey data (also costumer feedbacks etc') since the comments tend to have many \"suggestions\" in them, and the suggestions tend to apear positive to the model while the user suggests to improve something that needs improvement.\n",
    "For that end we trained a stance-model that handles suggestions well and labels each sentence as 'Positive', 'Negative', 'Neutral' and 'Suggestion'. We usually treat Suggestions as negatives and run two separate analysis, first over 'Positive' sentences and second over 'Negative' and 'Suggestions' sentences.\n",
    "\n",
    "This has the following advantages:\n",
    "* Creates a separate positive/negative summary that shows clearly what works well and what needs to be improved.\n",
    "* Filters-out neutral sentences that usually don't contain valuable information.\n",
    "* Helps the matching model avoid stance mistakes (matching a positive sentence to a negative key point and vice-versa).\n",
    "\n",
    "Lets run again, over the Austin survey dataset, but this time create two seperate KPA analyses (positive and negative). We will first need to create a new domain and add the domain_param **do_stance_analysis**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd950d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:02:11,232 [INFO] keypoints_client.py 424: client calls service (post): https://keypoint-matching-backend.debater.res.ibm.com/domains\n",
      "2022-09-22 12:02:12,147 [INFO] keypoints_client.py 475: created domain: austin_demo_two_stances with domain_params: {'do_stance_analysis': True}\n",
      "2022-09-22 12:02:12,149 [INFO] keypoints_client.py 270: domain: austin_demo_two_stances was created\n"
     ]
    }
   ],
   "source": [
    "domain = 'austin_demo_two_stances'\n",
    "domain_params = {'do_stance_analysis': True}\n",
    "KpAnalysisUtils.create_domain_ignore_exists(client=keypoints_client, domain=domain, domain_params=domain_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f04dd7e",
   "metadata": {},
   "source": [
    "Let's upload all 2016 comments to the new domain and wait for them to be processed. This time the sentences' stance is also calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bbbd3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:02:12,166 [INFO] keypoints_client.py 497: uploading 1588 comments in batches\n",
      "2022-09-22 12:02:12,169 [INFO] keypoints_client.py 424: client calls service (post): https://keypoint-matching-backend.debater.res.ibm.com/comments\n",
      "2022-09-22 12:02:13,378 [INFO] keypoints_client.py 511: uploaded 1588 comments, out of 1588\n",
      "2022-09-22 12:02:13,381 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/comments\n",
      "2022-09-22 12:02:14,104 [INFO] keypoints_client.py 523: domain: austin_demo_two_stances, comments status: {'processed_comments': 0, 'processed_sentences': 0, 'pending_comments': 1588}\n",
      "2022-09-22 12:02:24,111 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/comments\n",
      "2022-09-22 12:02:24,710 [INFO] keypoints_client.py 523: domain: austin_demo_two_stances, comments status: {'processed_comments': 1588, 'processed_sentences': 2708, 'pending_comments': 0}\n"
     ]
    }
   ],
   "source": [
    "comments_texts = [comment['text'] for comment in comments_2016]\n",
    "comments_ids = [comment['id'] for comment in comments_2016]\n",
    "keypoints_client.upload_comments(domain=domain, comments_ids=comments_ids, comments_texts=comments_texts)\n",
    "keypoints_client.wait_till_all_comments_are_processed(domain=domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bd699f",
   "metadata": {},
   "source": [
    "We can download the processed sentences and save them into a csv if we want to examine the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61f97380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:02:24,723 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/data\n",
      "2022-09-22 12:02:26,552 [INFO] keypoints_client.py 710: returning 2708 sentences for domain austin_demo_two_stances\n"
     ]
    }
   ],
   "source": [
    "sentences = keypoints_client.get_sentences_for_domain(domain=domain)\n",
    "KpAnalysisUtils.write_sentences_to_csv(sentences, f'{domain}_sentences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eae7368",
   "metadata": {},
   "source": [
    "And now, run two analyses, one over the positive sentences and one over the negative + suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11b6e4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:02:27,285 [INFO] keypoints_client.py 424: client calls service (post): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:02:28,055 [INFO] keypoints_client.py 579: started a kp analysis job - domain: austin_demo_two_stances, run_params: {'clustering_threshold': 0.95, 'mapping_threshold': 0.95, 'sentence_to_multiple_kps': True, 'stances_to_run': ['pos'], 'stances_threshold': 0.5}, job_id: 632c24a4116742ef7549707f\n",
      "2022-09-22 12:02:28,057 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:02:28,661 [INFO] keypoints_client.py 760: job_id 632c24a4116742ef7549707f is pending\n",
      "2022-09-22 12:02:58,674 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:02:59,748 [INFO] keypoints_client.py 767: job_id 632c24a4116742ef7549707f is done, returning result\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample positives coverage: 3.16\n",
      "Random sample positives key points:\n",
      "3 - RESIDENTIAL SERVICES ARE EXCELLENT!\n",
      "\t- City services (water, streets, electric) are outstanding!!\n",
      "\t- I was extremely impressed with the response time & professionalism of the workers!\n"
     ]
    }
   ],
   "source": [
    "run_params = {'clustering_threshold': 0.95, 'mapping_threshold': 0.95, \n",
    "              'sentence_to_multiple_kps': True}\n",
    "run_params['stances_to_run'] = ['pos']\n",
    "run_params['stances_threshold'] = 0.5\n",
    "future = keypoints_client.start_kp_analysis_job(domain=domain, run_params=run_params)\n",
    "kpa_pos_result = future.get_result(high_verbosity=True, polling_timout_secs=30)\n",
    "print_results(kpa_pos_result, n_sentences_per_kp=2, title='Random sample positives')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e9d628",
   "metadata": {},
   "source": [
    "As in many surveys, most comments are negative/suggestions therefore the positive analysis is relativly limited. Let's see how the negative analysis goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "160cbb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:02:59,764 [INFO] keypoints_client.py 424: client calls service (post): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:03:01,482 [INFO] keypoints_client.py 579: started a kp analysis job - domain: austin_demo_two_stances, run_params: {'clustering_threshold': 0.95, 'mapping_threshold': 0.95, 'sentence_to_multiple_kps': True, 'stances_to_run': ['neg', 'sug'], 'stances_threshold': 0.5}, job_id: 632c24c5116742ef75497082\n",
      "2022-09-22 12:03:01,485 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:03:02,080 [INFO] keypoints_client.py 760: job_id 632c24c5116742ef75497082 is pending\n",
      "2022-09-22 12:03:32,089 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:03:32,873 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 0, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |--------------------------------------------------| 0.0% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:04:02,885 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:04:03,574 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 0, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |--------------------------------------------------| 0.0% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:04:33,584 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:04:34,228 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 0, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |--------------------------------------------------| 0.0% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:05:04,236 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:05:04,882 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 7, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |███-----------------------------------------------| 7.4% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:05:34,891 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:05:35,573 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 20, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |██████████----------------------------------------| 21.3% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:06:05,583 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:06:06,210 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 20, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |██████████----------------------------------------| 21.3% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:06:36,222 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:06:36,885 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 22, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |███████████---------------------------------------| 23.4% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:07:06,888 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:07:07,541 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 28, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |██████████████------------------------------------| 29.8% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:07:37,549 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:07:38,211 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 40, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |█████████████████████-----------------------------| 42.6% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:08:08,216 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:08:08,923 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 40, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |█████████████████████-----------------------------| 42.6% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:08:38,925 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:08:39,541 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 42, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |██████████████████████----------------------------| 44.7% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:09:09,547 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:09:10,276 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 56, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |█████████████████████████████---------------------| 59.6% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:09:40,283 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:09:40,913 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 60, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |███████████████████████████████-------------------| 63.8% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:10:10,920 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:10:11,596 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 63, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |█████████████████████████████████-----------------| 67.0% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:10:41,602 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:10:42,273 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 68, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |████████████████████████████████████--------------| 72.3% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:11:12,280 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:11:12,906 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 80, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |██████████████████████████████████████████--------| 85.1% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:11:42,910 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:11:43,571 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 83, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |████████████████████████████████████████████------| 88.3% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:12:13,578 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:12:14,240 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 93, 'total_batches': 94, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1/2: |█████████████████████████████████████████████████-| 98.9% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:12:44,245 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:12:44,864 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 94, 'total_batches': 94, 'batch_size': 2000}, 'stage_2': {'inferred_batches': 0, 'total_batches': 8, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2/2: |--------------------------------------------------| 0.0% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:13:14,870 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:13:15,479 [INFO] keypoints_client.py 764: job_id 632c24c5116742ef75497082 is running, progress: {'total_stages': 2, 'stage_1': {'inferred_batches': 94, 'total_batches': 94, 'batch_size': 2000}, 'stage_2': {'inferred_batches': 4, 'total_batches': 8, 'batch_size': 2000}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2/2: |█████████████████████████-------------------------| 50.0% Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:13:45,486 [INFO] keypoints_client.py 424: client calls service (get): https://keypoint-matching-backend.debater.res.ibm.com/kp_extraction\n",
      "2022-09-22 12:13:47,575 [INFO] keypoints_client.py 767: job_id 632c24c5116742ef75497082 is done, returning result\n"
     ]
    }
   ],
   "source": [
    "run_params['stances_to_run'] = ['neg', 'sug']\n",
    "run_params['stances_threshold'] = 0.5\n",
    "future = keypoints_client.start_kp_analysis_job(domain=domain, run_params=run_params, comments_ids=comments_ids)\n",
    "kpa_neg_result = future.get_result(high_verbosity=True, polling_timout_secs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8121d10b",
   "metadata": {},
   "source": [
    "Lets print the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8015b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sample negatives coverage: 70.91\n",
      "Random sample negatives key points:\n",
      "541 - Address transportation problems NOW.\n",
      "\t- PLEASE FIX THE TRAFFIC PROBLEMS, TOLL ROADS ARE NOT THE ANSWER\n",
      "\t- PLEASE WORK ON TRAFFIC.\n",
      "294 - Work on making Austin affordable again.\n",
      "\t- The lack of affordable housing in Austin has pushed many of the original Austinites out\n",
      "\t  of the city.\n",
      "\t- PLEASE KEEP THE COST OF LIVING IN AUSTIN AFFORDABLE SO WE CAN STAY\n",
      "140 - Property taxes are outrageous.\n",
      "\t- PROPERTY TAX OUTRAGEOUS!\n",
      "\t- PROPERTY TAXES ARE TOO HIGH.\n",
      "138 - Spend our tax dollars wisely!!!\n",
      "\t- I can no longer afford to live in Austin due to the high property taxes-look for, find\n",
      "\t  and eliminate tax dollar waste!\n",
      "\t- Cost, waste,, us taxpayers a lot.\n",
      "129 - Better pedestrian and biking lifestyle options.\n",
      "\t- CONSIDER BETTER DEVELOPED BIKE LANES THROUGHOUT THE CITY.\n",
      "\t- PUBLIC MASS TRANSIT,HOV,BIKE LANES AND WALKABLE NEIGHBORHOODS.\n",
      "129 - SMARTER TRAFFIC MANAGEMENT.\n",
      "\t- I would like to gave seen the money I paid go towards improving our traffic\n",
      "\t  structure/management both in and around downtown Austin.\n",
      "\t- Look at the terrible traffic problem & stop building more apartments.\n",
      "124 - Enforce the traffic laws.\n",
      "\t- Fix the pot holes in the roads and make the police follow and enforce traffic laws.\n",
      "\t- ENFORCEMENT OF TRAFFIC LAWS TO KEEP TRAFFIC FLOWING.\n",
      "124 - electric rates are too high\n",
      "\t- The electric bill rates are getting too high and are not as affordable as they were in\n",
      "\t  the past.\n",
      "\t- Rates are to high\n",
      "113 - effective rail is desperately needed.\n",
      "\t- WE NEED A BETTER LIGHT RAIL OR GONDALAS\n",
      "\t- NEED BETTER RAIL SYSTEM.\n",
      "85 - more pedestrian safety\n",
      "\t- WE NEED BETTER SIDEWALKS AND LIGHTING.\n",
      "\t- MORE SIDEWALKS AND STREET LIGHTS.\n",
      "59 - Improve the auto circulation.\n",
      "\t- Get the bikes off the streets and improve traffic flow in and out of the city.\n",
      "\t- Traffic signals need to be synchronized to provide for better flow of traffic around the\n",
      "\t  city.\n",
      "56 - Effective, affordable ride-share networks are critical.\n",
      "\t- Develop public transportation network.\n",
      "\t- Better local transportation including ride share companies as reasonable options.\n",
      "55 - TO HAVE BETTER PLANNING FOR CITY GROWTH.\n",
      "\t- Plan out the growth for Austin as the city grows.\n",
      "\t- Need to plan for the growth and traffic this city is now experiencing much better.\n",
      "54 - make every effort to eradicate poverty\n",
      "\t- PROTECT EAST AUSTIN AND THE POOR\n",
      "\t- Affordable housing for middle and low income families not based off average income levels.\n",
      "38 - Focus on efficient solutions.\n",
      "\t- FOCUS ON EFFICIENT SOLUTIONS.\n",
      "\t- Review all departments for waste, duplication, inefficiency, etc so that the City will\n",
      "\t  be better stewards of our tax dollars.\n",
      "35 - The permitting process has got to improve.\n",
      "\t- Please fix building permit processes, it's crooked!\n",
      "\t- Have permits for new commercial build outs be processed faster.\n",
      "29 - Do something to increase diversity here.\n",
      "\t- Attract a most diverse population to Austin\n",
      "\t- Please keep housing affordable for artists, minorities, low income, young people, and\n",
      "\t  keep Austin diverse!\n",
      "29 - Stop the gentrification.\n",
      "\t- STOP THE GENTRIFICATION.\n",
      "\t- Small businesses, small homes, middle and low income families are being priced out and\n",
      "\t  even in the few years I've been here, I sometimes don't recognize Austin.\n",
      "28 - Make homelessness a top priority.\n",
      "\t- TAKE BETTER CARE OF THE HOMELESS!\n",
      "\t- THE CITY NEED TO MAKE AFFORDABLE HOUSING PRIORITY.\n",
      "21 - Protect local businesses.\n",
      "\t- Stop letting people and business move here.\n",
      "\t- KEEP AUSTIN WEIRD & MAKE SURE TO SUPPORT LOCAL BUSINESS AND MUSIC\n"
     ]
    }
   ],
   "source": [
    "print_results(kpa_neg_result, n_sentences_per_kp=2, title='Random sample negatives')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e4a64",
   "metadata": {},
   "source": [
    "Reaching a nice 70.9% coverage, most of the sentences are matched to the 20 automatically extracted key points.\n",
    "\n",
    "We can increase the stances_threshold when we want to run over less sentences with a stronger stance. This is useful when we have a large dataset with many less-relevant sentences and we want to filter them out.\n",
    "\n",
    "We can mark the stance in the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b27b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpa_pos_result = KpAnalysisUtils.set_stance_to_result(kpa_pos_result, 'pos')\n",
    "kpa_neg_result = KpAnalysisUtils.set_stance_to_result(kpa_neg_result, 'neg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d9976f",
   "metadata": {},
   "source": [
    "And save the results (both pos/neg seperatly and merged) and create key points graphs' data files as we did before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c03646d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 12:13:47,590 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_pro_kpa_results_kps_summary.csv\n",
      "2022-09-22 12:13:47,593 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_pro_kpa_results.csv\n",
      "2022-09-22 12:13:47,596 [INFO] keypoints_client.py 355: Creating key points graph data-file for results file: austin_survey_2016_pro_kpa_results.csv\n",
      "2022-09-22 12:13:47,596 [INFO] keypoints_client.py 330: reading file: austin_survey_2016_pro_kpa_results.csv\n",
      "2022-09-22 12:13:47,602 [INFO] keypoints_client.py 388: saving graph in file: austin_survey_2016_pro_kpa_results_graph_data.json\n",
      "2022-09-22 12:13:47,602 [INFO] keypoints_client.py 389: saving graph in file: austin_survey_2016_pro_kpa_results_graph_data.json\n",
      "2022-09-22 12:13:47,633 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_neg_kpa_results_kps_summary.csv\n",
      "2022-09-22 12:13:47,639 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_neg_kpa_results.csv\n",
      "2022-09-22 12:13:47,665 [INFO] keypoints_client.py 355: Creating key points graph data-file for results file: austin_survey_2016_neg_kpa_results.csv\n",
      "2022-09-22 12:13:47,666 [INFO] keypoints_client.py 330: reading file: austin_survey_2016_neg_kpa_results.csv\n",
      "2022-09-22 12:13:47,740 [INFO] keypoints_client.py 388: saving graph in file: austin_survey_2016_neg_kpa_results_graph_data.json\n",
      "2022-09-22 12:13:47,740 [INFO] keypoints_client.py 389: saving graph in file: austin_survey_2016_neg_kpa_results_graph_data.json\n",
      "2022-09-22 12:13:47,763 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_merged_kpa_results_kps_summary.csv\n",
      "2022-09-22 12:13:47,768 [INFO] keypoints_client.py 115: Writing dataframe to: austin_survey_2016_merged_kpa_results.csv\n",
      "2022-09-22 12:13:47,792 [INFO] keypoints_client.py 355: Creating key points graph data-file for results file: austin_survey_2016_merged_kpa_results.csv\n",
      "2022-09-22 12:13:47,793 [INFO] keypoints_client.py 330: reading file: austin_survey_2016_merged_kpa_results.csv\n",
      "2022-09-22 12:13:47,886 [INFO] keypoints_client.py 388: saving graph in file: austin_survey_2016_merged_kpa_results_graph_data.json\n",
      "2022-09-22 12:13:47,887 [INFO] keypoints_client.py 389: saving graph in file: austin_survey_2016_merged_kpa_results_graph_data.json\n"
     ]
    }
   ],
   "source": [
    "pos_result_file = 'austin_survey_2016_pro_kpa_results.csv'\n",
    "KpAnalysisUtils.write_result_to_csv(kpa_pos_result, pos_result_file)\n",
    "KpAnalysisUtils.create_graph_data_file_for_ui(pos_result_file)\n",
    "\n",
    "neg_result_file = 'austin_survey_2016_neg_kpa_results.csv'\n",
    "KpAnalysisUtils.write_result_to_csv(kpa_neg_result, neg_result_file)\n",
    "KpAnalysisUtils.create_graph_data_file_for_ui(neg_result_file)\n",
    "\n",
    "kpa_merged_result = KpAnalysisUtils.merge_two_results(kpa_pos_result, kpa_neg_result)\n",
    "merged_result_file = 'austin_survey_2016_merged_kpa_results.csv'\n",
    "KpAnalysisUtils.write_result_to_csv(kpa_merged_result, merged_result_file)\n",
    "KpAnalysisUtils.create_graph_data_file_for_ui(merged_result_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2922bee",
   "metadata": {},
   "source": [
    "We can also use the incremental approach when running on each stance seperatly. We will need to provide the job_id of the positive analysis of 2016 when running on the positive sentences of 2016 + 2017 and the job_id of negative analysis of 2016 when running on the negative sentences of 2016 + 2017, but for simplicity reasons, we didn't combine the features in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd476d4",
   "metadata": {},
   "source": [
    "## 5. Cleanup\n",
    "If you finished the tutorial and no longer need the domains and the results, or want to run the tutorial again from scratch, delete the domains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27faf5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_domains = False\n",
    "if delete_domains:\n",
    "    KpAnalysisUtils.delete_domain_ignore_doesnt_exist(client=keypoints_client, domain='austin_demo')\n",
    "    KpAnalysisUtils.delete_domain_ignore_doesnt_exist(client=keypoints_client, domain='austin_demo_two_stances')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dbc94e",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "In this tutorial, we showed how to use the *Key Point Analysis* service, and how it provides detailed insights over survey data right out of the box - significantly reducing the effort required by a data scientist to analyze the data. We also demonstrated key *key point analysis* features such as how to modify the analysis parameters and increase coverage, how to use the stance-model and create per-stance results, how to create *key points graph* and further improve the quality and the clarity of the results, and how to incrementally add new data.\n",
    "\n",
    "Feel free to contact us for questions or assistance: *yoavka@il.ibm.com*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kpa_env",
   "language": "python",
   "name": "kpa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
